{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHHEL56GbG05+SKX6ltfJT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pSoAxgETMmIp","executionInfo":{"status":"ok","timestamp":1744716030190,"user_tz":-300,"elapsed":25037,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision import transforms\n","from torchsummary import summary\n","from torch.utils.data import DataLoader,Dataset\n","from PIL import Image\n","import keras\n","from numpy import load\n","import torch.nn.functional as F\n","\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds"],"metadata":{"id":"hlgqqP2zsPYx","executionInfo":{"status":"ok","timestamp":1744716030649,"user_tz":-300,"elapsed":462,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = '/content/drive/MyDrive/'\n","\n","import os\n","\n","directory = '/content/drive/My Drive/FPIS/IMG/'\n","IMG = os.listdir(directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsXzc2YQs_bI","executionInfo":{"status":"ok","timestamp":1744716053163,"user_tz":-300,"elapsed":22513,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"0f9c99d4-651a-478e-a9d5-a0b7f31d812c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","from torch.utils.data import TensorDataset\n","# Аугментации\n","transform = transforms.Compose([\n","    transforms.RandomResizedCrop(244),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(20),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","augmented_images = []\n","\n","for filename in tqdm(IMG):\n","    filepath = os.path.join(directory, filename)\n","    try:\n","        image = Image.open(filepath).convert('RGB')\n","        for _ in range(20):  # 20 копий каждого изображения → 100 x 20 = 2000\n","            augmented = transform(image)\n","            augmented_images.append(augmented)\n","    except Exception as e:\n","        print(f\"Ошибка с файлом {filename}: {e}\")\n","\n","# Собираем всё в один тензор и оборачиваем в Dataset\n","dataset_tensor = torch.stack(augmented_images)\n","ds = TensorDataset(dataset_tensor)\n","\n","print(f\" Всего изображений в датасете: {len(ds)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cNCfk2JStQtH","executionInfo":{"status":"ok","timestamp":1744716061250,"user_tz":-300,"elapsed":8084,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"57f3fe10-a462-43f4-cac4-872e2c04e2fa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:07<00:00, 13.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":[" Всего изображений в датасете: 2000\n"]}]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","# Размеры\n","total_size = len(ds)\n","train_size = int(0.8 * total_size)\n","val_size = total_size - train_size\n","\n","# Разбиваем\n","train_ds, val_ds = random_split(ds, [train_size, val_size])\n","\n","print(f\" Train: {len(train_ds)} | Val: {len(val_ds)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egd7geeushJ8","executionInfo":{"status":"ok","timestamp":1744716061261,"user_tz":-300,"elapsed":20,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"0443bbea-faaa-4698-a77c-3ab4ba8ae7b9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[" Train: 1600 | Val: 400\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n"],"metadata":{"id":"vol7lpRuusDA","executionInfo":{"status":"ok","timestamp":1744716061273,"user_tz":-300,"elapsed":11,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from torchvision import models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if device.type == 'cuda':\n","    print(f\"Используется GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    print(\"Используется CPU\")\n","\n","# Загружаем предобученную ResNet18\n","model = models.resnet18(pretrained=True)\n","\n","# Меняем последний слой на 100 классов\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, 100)  # <- 100 классов\n","\n","model = model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrqRqVrgqe1m","executionInfo":{"status":"ok","timestamp":1744716062063,"user_tz":-300,"elapsed":795,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"44dc3801-7309-48e6-a668-6b8e33db46bb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Используется GPU: Tesla T4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 169MB/s]\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)"],"metadata":{"id":"TqwScZp-quXa","executionInfo":{"status":"ok","timestamp":1744716062108,"user_tz":-300,"elapsed":39,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for inputs, in tqdm(train_loader, desc=f\" Epoch {epoch+1}/{num_epochs}\"):\n","        inputs = inputs.to(device)\n","        labels = torch.randint(0, 100, (inputs.size(0),)).to(device)  # Заменить на реальные метки, если есть\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    avg_loss = running_loss / len(train_loader)\n","    print(f\"Loss: {avg_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36_0qdFIvdEH","executionInfo":{"status":"ok","timestamp":1744716122480,"user_tz":-300,"elapsed":60367,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"807004f0-44af-41e2-9400-283b3a169ab9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":[" Epoch 1/10: 100%|██████████| 50/50 [00:07<00:00,  6.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.7299\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 2/10: 100%|██████████| 50/50 [00:05<00:00,  8.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6498\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 3/10: 100%|██████████| 50/50 [00:06<00:00,  8.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6466\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 4/10: 100%|██████████| 50/50 [00:05<00:00,  8.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6477\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 5/10: 100%|██████████| 50/50 [00:05<00:00,  8.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6354\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 6/10: 100%|██████████| 50/50 [00:05<00:00,  8.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6260\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 7/10: 100%|██████████| 50/50 [00:05<00:00,  8.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6350\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 8/10: 100%|██████████| 50/50 [00:05<00:00,  8.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6241\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 9/10: 100%|██████████| 50/50 [00:05<00:00,  8.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6309\n"]},{"output_type":"stream","name":"stderr","text":[" Epoch 10/10: 100%|██████████| 50/50 [00:05<00:00,  8.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Loss: 4.6254\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","\n","def predict_image(image_path, model, device):\n","    image = Image.open(image_path).convert('RGB')\n","    image = transform(image).unsqueeze(0).to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(image)\n","    _, predicted_class = torch.max(outputs, 1)\n","    return predicted_class.item()\n","\n","\n","class_images = {i: [] for i in range(100)}\n","\n","# Предположим, что у вас есть список всех изображений\n","image_names = os.listdir(directory)\n","\n","# Применяем предсказание ко всем изображениям\n","for filename in tqdm(image_names):\n","    image_path = os.path.join(directory, filename)\n","    predicted_class = predict_image(image_path, model, device)\n","    class_images[predicted_class].append(filename)  # Храним название файла\n","\n","\n","def show_class_image_names(class_id, class_images, num_images):\n","    images = class_images[class_id]\n","    print(f\"Изображения, отнесенные к классу {class_id}:\")\n","    for i, img_name in enumerate(images[:num_images]):  # Отображаем первые 5 названий\n","        print(f\"{i + 1}. {img_name}\")\n","\n","\n","def display_images_for_image(image_name, class_images, model, device, directory):\n","    image_path = os.path.join(directory, image_name)\n","\n","    if not os.path.exists(image_path):\n","        print(f\"Ошибка: файл с именем {image_name} не найден.\")\n","        return\n","\n","\n","    predicted_class = predict_image(image_path, model, device)\n","    print(f\"Изображение '{image_name}' отнесено к классу {predicted_class}.\")\n","\n","\n","    show_class_image_names(predicted_class, class_images, num_images=20)\n","\n","# Запрашиваем имя изображения у пользователя\n","image_name_input = 'V $ X V PRiNCE - Дом 50.png'\n","\n","# Отображаем названия изображений для этого класса\n","display_images_for_image(image_name_input, class_images, model, device, directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKiC8_98-7CU","outputId":"65d74146-f5bd-4c23-f13e-24c4b78caf7f","executionInfo":{"status":"ok","timestamp":1744716123569,"user_tz":-300,"elapsed":1086,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:01<00:00, 93.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Изображение 'V $ X V PRiNCE - Дом 50.png' отнесено к классу 95.\n","Изображения, отнесенные к классу 95:\n","1. MACAN - IVL.png\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/resnet_music.pth')\n","print(\"Модель сохранена!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deAyrgn-LdtB","executionInfo":{"status":"ok","timestamp":1744716126330,"user_tz":-300,"elapsed":131,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"fa5c265d-44a6-48ef-abfe-70660dfc36de"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Модель сохранена!\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","from collections import defaultdict\n","\n","# Предположим, структура такая:\n","# /path/to/data/class_0/song1.png\n","# /path/to/data/class_1/song2.png\n","\n","root_dir = \"/content/drive/MyDrive/FPIS/IMG/\"\n","class_to_songs = defaultdict(list)\n","\n","for root, dirs, files in os.walk(root_dir):\n","    for file in files:\n","        if file.endswith(\".png\"):\n","            class_name = os.path.basename(root)\n","            class_to_songs[class_name].append(file)\n","\n","# Преобразуем строковые ключи классов в числовые, если нужно\n","class_to_index = {cls: idx for idx, cls in enumerate(sorted(class_to_songs))}\n","index_to_songs = {class_to_index[k]: v for k, v in class_to_songs.items()}\n","\n","# Сохраняем словарь\n","with open(\"class_to_songs.json\", \"w\") as f:\n","    json.dump(index_to_songs, f)\n"],"metadata":{"id":"Dez5lRdPO_Tu","executionInfo":{"status":"ok","timestamp":1744716978373,"user_tz":-300,"elapsed":4,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Скачивание из виртуальной среды\n","from google.colab import files\n","files.download('class_to_songs.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Eeau92KkPy1F","executionInfo":{"status":"ok","timestamp":1744717194723,"user_tz":-300,"elapsed":9,"user":{"displayName":"Напылов Иван","userId":"13909619839180631397"}},"outputId":"e01d85a2-a0ba-4e96-c660-05df5edeb76c"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a7a00d49-4dac-48eb-b003-f75fd438f204\", \"class_to_songs.json\", 6736)"]},"metadata":{}}]}]}